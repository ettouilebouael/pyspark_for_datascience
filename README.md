# **PySpark pour la Data Science**  

Bienvenue dans le repository du cours **PySpark pour la Data Science**. Ce cours explore les concepts fondamentaux et avancÃ©s de PySpark Ã  travers des exemples pratiques et des cas d'utilisation liÃ©s Ã  la data science.  

## ğŸ“‹ **Table des matiÃ¨res**  

- [Ã€ propos du cours](#-Ã -propos-du-cours)  
- [PrÃ©requis](#-prÃ©requis)
- [Organisation](#-organisation)
- [Structure du repository](#-structure-du-repository)
- [Recommandations de lecture](#-recommandations-de-lecture)
- [Contact](#-contact)

## ğŸ¯ **Ã€ propos du cours**  

Ce cours a Ã©tÃ© conÃ§u pour :  
- Introduire les fondamentaux de PySpark, y compris son architecture, ses principes du calcul distribuÃ©, ainsi que la manipulation des RDDs et DataFrames.
- Explorer des applications de PySpark dans la data science : nettoyage de donnÃ©es, analyses exploratoires, feature engineering et modÃ©lisation.  
- Introduire des concepts avancÃ©s tels que les fonctions fenÃªtre, les optimisations de code, et le machine learning avec MLlib.  

## ğŸ’» **PrÃ©requis**  

Avant de commencer, assurez-vous de disposer des Ã©lÃ©ments suivants : 

- **CompÃ©tences non-techniques** :
  - Une forte motivation et un goÃ»t prononcÃ© pour le challenge.
  - CapacitÃ© Ã  analyser des problÃ¨mes de maniÃ¨re logique et structurÃ©e.
  - CuriositÃ© intellectuelle et envie dâ€™explorer de nouveaux concepts.

- **CompÃ©tences techniques** :
  - Niveau dÃ©butant-intermÃ©diare en Python et ses bibliothÃ¨ques associÃ©es : Pandas et Scikit-learn
  - Niveau dÃ©butant-intermÃ©diare en SQL
  - ComprÃ©hension des algorithmes de machine learning, notamment la rÃ©gression linÃ©aire et les modÃ¨les basÃ©s sur les arbres de dÃ©cision.
    
- **Environnement de travail** :
Vous pouvez choisir parmi les options suivantes :
  - En local sur votre machine :
    - Python 3.8 ou une version ultÃ©rieure.
    - Apache Spark 3.x.
    - Un Ã©diteur comme Jupyter Notebook ou un IDE tel que VS Code.
  - Sur Google Colab
  - Sur Databricks

## ğŸ“… **Organisation**  

- TD1 (2H) : Introduction Ã  Apache Spark et comprÃ©hension de ses principes.
- TD2 (2H) : DÃ©veloppement de processus d'analyse de donnÃ©es et de Feature Engineering avec Spark SQL.
- TD3 (2H) : DÃ©veloppement avancÃ© de processus d'analyse de donnÃ©es et de Feature Engineering avec Spark SQL.
- TD4 (2H) : EntraÃ®nement distribuÃ© d'algorithmes de Machine Learning avec Spark MLlib.
- TD5 (2H) : Ã‰valuation + Feedback sur les livrables

## ğŸ“‚ **Structure du repository**
    .
    pyspark-data-science/
    â”œâ”€â”€ data/           # DonnÃ©es utilisÃ©es dans les cours et exercices
    â”œâ”€â”€ cours/          # Slides ou Notebooks Jupyter pour les sessions de cours  
    â”œâ”€â”€ td_Ã©noncÃ©s/     # Exercices pratiques
    â”œâ”€â”€ td_corrigÃ©s/    # Correction des exercices pratiques
    â”œâ”€â”€ dm/             # Solutions des devoirs maisons
    â””â”€â”€ README.md       # Ce fichier

## ğŸ“š **Recommandations de lecture**  

Voici quelques ressources utiles :  

- **Documentation officielle de PySpark** : [Lien](https://spark.apache.org/docs/latest/api/python/index.html)  
- **Principes de base de PySpark (Databricks)** : [Lien](https://learn.microsoft.com/fr-fr/azure/databricks/pyspark/basics)  
- **Feature Engineering pour la prÃ©vision de sÃ©ries temporelles (Medium)** :  [Lien](https://medium.com/@soyoungluna/tutorial-feature-engineering-for-weekly-time-series-forecasting-in-pyspark-b207c41869f4)  
- **Regression with gradient-boosted trees and MLlib pipelines (Databricks)** : [Lien](https://docs.databricks.com/en/_extras/notebooks/source/gbt-regression.html)

## ğŸ’¡ **Contact**
Pour toute question ou suggestion, contactez-moi Ã  ouael@mailbox.org ou ouvrez une issue sur ce repository.


 
